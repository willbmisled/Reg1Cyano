---
title: "Region1CyanoLocations2014"
author: "Bryan Milstead"
date: "March 18, 2015"
output: html_document
---
<!---
use these command instead of the knit icon if you want the data and work loaded into the R workspace
  library(knitr)
    setwd("Data2014")
    knit('Locations2014.rmd')
  -->
```{r setup, include=FALSE, echo=FALSE, cache=FALSE} 
  #########function to install (if needed) and load R packages by list
libs<-c("rgdal","sp","knitr","maptools","rgeos") #list of packages to load

installLoad<-function(pck){ #user defined function
    if(!pck%in%installed.packages()){install.packages(pck)}
    require(pck, character.only = TRUE)
  }
lapply(libs,function(x) installLoad(x))  #Load/Install require packages
```

To Do List
-------------------------
* check locations manually for distance >0
* Map locations and send to contacts for verifications

Introduction
-------------------------
During the summer of 2014 the New England states initiated a monitoring program for cyanobacteria in lakes.  Participants included state and tribal governments, local watershed associations, EPA Region 1, and the EPA Atlantic Ecology Division. 

The data have been standardized and are available here in .csv format (hint: right click on the link and choose “Save As” to save the file to your computer, otherwise, it will open in your browser): https://github.com/willbmisled/Reg1Cyano/blob/master/Data2014/Data2014.csv?raw=true

The details of the data processing steps can be found here: https://github.com/willbmisled/Reg1Cyano/blob/master/Data2014/Data2014.md

This document is available here: https://github.com/willbmisled/Reg1Cyano/blob/master/Data2014/Locations2014.md

A KML file for view in Google Earth is available here (hint: right click on the link and choose “Save As” to save the file to your computer, otherwise, it will open in your browser): https://github.com/willbmisled/Reg1Cyano/blob/master/Data2014/Locations.kml?raw=true

An R datafile with a the Locations in SpatialPointsDataframe format is available here (hint: right click on the link and choose “Save As” to save the file to your computer, otherwise, it will open in your browser): https://github.com/willbmisled/Reg1Cyano/blob/master/Data2014/Locations.rda?raw=true

Data Definitions SpatialPointsDataFrame "Locations" in "Locations.rda" 
-------------------------

Field  | Units | Description
------------- | ------------- | -------------
**Longitude:**|(Decimal Degrees)|Longitude of Location
**Latitude:**|(Decimal Degrees)|Latitude of Location
**LocID:**|(Integer)|Unique identifier for location
**WBID:**|(Integer)|Unique identifier for closest lake to location
**Distance:**|(Meters)|Distance from Location to nearest lake

Data Sources
-------------------------
The field data, including location information, have been standardized and are available here in .csv format (hint: right click on the link and choose “Save As” to save the file to your computer, otherwise, it will open in your browser): https://github.com/willbmisled/Reg1Cyano/blob/master/Data2014/Data2014.csv?raw=true

The details of the data processing steps and the data definitions can be found here: https://github.com/willbmisled/Reg1Cyano/blob/master/Data2014/Data2014.md

This document is available here: https://github.com/willbmisled/Reg1Cyano/blob/master/Data2014/Locations2014.md

Data Steps
-------------------------

* Download the data 
* Check which data (excluding blanks and standards) are missing locations
* Created NHDES_MissingLocation.csv & UNH_MissingLocation.csv

```{r missing, include=FALSE, echo=FALSE, cache=FALSE}
#Download the data 
  Data2014<-read.csv("Data2014.csv")
#select samples only
  unique(Data2014$SampleMethod)
  a<-Data2014[Data2014$SampleMethod=='Grab'|Data2014$SampleMethod=='VanDorn'|Data2014$SampleMethod=='Integrated',]
#which locations are missing
  table(is.na(a$Latitude)) #0 missing  N=8499
```

* Keep only the unique long lat data 
* Create a SpatialPointsDataFrame

```{r spdf, include=FALSE, echo=FALSE, cache=FALSE} 
#Unique location data
  Loc<-unique(na.exclude(Data2014[,c("LocID","Longitude","Latitude")])) 

#create spatial points dataframe
  WGS84<-CRS("+proj=longlat +datum=WGS84")  #ESRI GCS_WGS_1984 
  Loc<-SpatialPointsDataFrame(coordinates(Loc[,-1]), Loc, proj4string=WGS84)
plot(Loc)

#transform to Albers
  #ESRI USA Contiguous Albers Equal Area Conic (used by MRB1 WBIDLakes as AlbersX and AlbersY)
  AlbersContiguous<-CRS('+proj=aea +x_0=0 +y_0=0 +lon_0=-96 +lat_1=29.5 +lat_2=45.5 +lat_0=37.5 +units=m +datum=NAD83')
    LocA<-spTransform(Loc,AlbersContiguous) #reproject
```

* Get MRB1_WBIDLakes from the WaterbodyDatabase.mdb
* Reproject to WGS84
* Fix holes (just in case)
* Cache this XXX

```{r getLakes, include=FALSE, echo=FALSE, cache=TRUE} 
  #MDB<-"c:/Users/FrayJorge/My Documents/EPA/Data/WaterbodyDatabase/WaterbodyDatabase.mdb" #data source
  MDB<-"c:/Bryan/EPA/Data/WaterbodyDatabase/WaterbodyDatabase.mdb" #data source
  features <- ogrListLayers(dsn=MDB) #MRB1_WBIDLakes
  Lakes<-readOGR(dsn=MDB,'MRB1_WBIDLakes')
  Lakes<-spTransform(Lakes,WGS84) #reproject
  #Associate lake holes (islands) with the correct polygon.  This is an important step.
    slot(Lakes, "polygons") <- lapply(slot(Lakes, "polygons"), checkPolygonsHoles)

#transform to Albers
     LakesA<-spTransform(Lakes,AlbersContiguous) #reproject
```

* Find the closest lake to each point
* First buffer the points by 1000 meters
* Use Over to select lakes within the buffer
* Use gDistance to find closest lake to each point
* If no lakes are found iteratively, increase the buffer distance up to 50km.
* Cache this XXX

```{r gDist, include=FALSE, echo=FALSE, cache=FALSE} 
#buffer points and select lakes within the buffer.
  #dataframe to hold results
    WBID<-data.frame(WBID=rep(NA,nrow(LocA)),Distance=rep(NA,nrow(LocA)))  
  #loop through the point locations
    for(i in 1:nrow(LocA)) {  
      #select Point
        pt<-LocA[i,]
      #While Loop to select Lakes  
        BufLakes<-data.frame() #reset BufLakes
        D<-1000 #reset buffer distance
        #start Loop
         while(nrow(BufLakes)==0) {
          if (D>50001) break #stop if D greater than 50km
          #Buffer Point
            Buf<-gBuffer(pt,width=D)
          #increase buffer width for next run
            D<-D+10000 
          #Select Lakes within Buffer-returns empty data.frame if no lakes are selected
            BufLakes<-tryCatch(LakesA[unlist(over(Buf, LakesA, returnList = TRUE)),],error = function(e) data.frame())    
          }      
      # find closest BufLake to point with gDistance
        if(nrow(BufLakes)>0){
            a<-vector() #empty work vector
          for(j in 1:nrow(BufLakes)) {  #loop through the BufLakes
            a<- append(a, gDistance(LocA[i,],BufLakes[j,])) #vector with distance from pt to each lake
            Dist<-min(a) #distance to closest lake
            WB<-BufLakes@data$WB_ID[which(a==Dist)] #WBID for closest lake
            b<-data.frame(WBID=WB,Distance=Dist) #output
          }
        }else{
            b<-data.frame(WBID=NA,Distance=NA) #output = NA
        }
        WBID[i,]<-b #add output to results df
    } 

  #add to Loc and LocA
    Loc@data$WBID<-WBID$WBID
    Loc@data$Distance<-WBID$Distance
    LocA@data$WBID<-WBID$WBID
    LocA@data$Distance<-WBID$Distance

```

* Create KML and SHP files of locations

```{r KML, include=FALSE, echo=FALSE, cache=FALSE}
#create KML file of location          
  kmlPoints(Loc, 
            kmlfile='Locations.kml', 
            name=formatC(Loc$LocID, width=3, flag="0"), 
            description=paste("WBID",Loc@data$WBID),
            icon="http://maps.google.com/mapfiles/kml/paddle/ltblu-stars.png",
            kmlname="Locations",
            kmldescription="Region 1 CyanoMonitoring Locations")
#open file in google earth
  #shell.exec('Locations.kml')


#save shapefile
writeOGR(Loc,getwd(),'Locations', driver="ESRI Shapefile",overwrite_layer=TRUE)
  
```

* create an output file to check locations and location information
* save as 'tempLocations.csv'

```{r verfiyLoc, include=FALSE, echo=FALSE, cache=FALSE}
# merge locations with Data2014 to get the location information
  a<-merge(Data2014,Loc@data[,c("LocID","WBID","Distance")],by='LocID',all.x=FALSE)
# get the unique site information
  b<-unique(a[,c("Organization","LocID","Longitude","Latitude","WaterbodyName","SiteID","SiteLocation","SampleLocation","WBID","Distance")]);nrow(b) #333
#add freqLocID: the number of times each LocID is include.
  x<-as.data.frame(table(b$LocID))
    names(x)<-c("LocID","freqLocID")
  b<-merge(b,x,by='LocID')
#add freqWBID: the number of times each WBID is include.
  x<-as.data.frame(table(b$WBID))
    names(x)<-c("WBID","freqWBID")
  b<-merge(b,x,by='WBID')
#save
  write.table(b, file='tempLocations.csv',row.names=F,sep=',') #write to csv
```

* tempLocations.csv manually reviewed in excel
* Locations.kml verified in Google Earth
  - shell.exec('Locations.kml')
* names checked
* LocIDNew field added to aggregrate Sites with multiple location observations
* siteDescriptions simplified-manually.
* file resaved as tempLocations1.csv
* locations with distances to WBID greater than 20m verified in ArcGIS & GE
* LocID=11 Lon/Lat changed from -73.078158 / 45.340375; moved to offshore Phillpsburg
  - shell.exec('Locations.mxd')
* check that each there is only one siteDescription for each LocIDNew
* check that each there is only one WBID for each LocIDNew
* get unique LocIDNew information
* rename Lon/Lat 'Lon_LocIDNew' & 'Lat_LocIDNew'
* add WBID centroids 'Lon_WBID' & 'Lat_WBID'
* add WBID Centroids for Charles River sites (no WBID) (estimated from GE)
* make final locations files
  - "LocIDNew" a SpatialPointDataFrame with the unique aggregated locations and site information
  - "LocIDNew.kml" kml file of the locations
  - "LocIDNew.shp" shapefile of the locations  
  - "LocID2LocIDNew" crosswalk of the information in in LocIDNew to the original LocID in Data2014
* save data as Locations.rda

```{r SaveData, include=FALSE, echo=FALSE, cache=FALSE}
#read the data
  a<-read.csv("tempLocations1.csv")
#check that each there is only one siteDescription for each LocIDNew
  b<-unique(a[,c('LocIDNew','siteDescription')])
  x<-as.data.frame(table(b$LocIDNew))
  x[x$Freq>1,]
#check that each there is only one WBID for each LocIDNew
  b<-unique(a[,c('LocIDNew','WBID')])
  x<-as.data.frame(table(b$LocIDNew))
  x[x$Freq>1,]
#get unique LocIDNew information
  b<-unique(a[a$LocID==a$LocIDNew,c("LocIDNew","WBID","Longitude","Latitude","siteDescription","siteComment")]);nrow(b) #183
    names(b)[3:4]<-c('Lon_LocIDNew','Lat_LocIDNew')
# add WBID centroids 'Lon_WBID' & 'Lat_WBID'
  b<-merge(b,Lakes@data[,c('WB_ID','Centroid_Long','Centroid_Lat')],by.x='WBID',by.y='WB_ID',all.x=TRUE);nrow(b) #183
    names(b)[7:8]<-c('Lon_WBID','Lat_WBID')
  LocIDNew<-SpatialPointsDataFrame(coordinates(b[,3:4]), b, proj4string=WGS84)
  #add centroids for missing WBID
    LocIDNew$Lon_WBID[is.na(LocIDNew$WBID)]<--71.076827
    LocIDNew$Lat_WBID[is.na(LocIDNew$WBID)]<-42.359977
    
#create KML file        
  kmlPoints(LocIDNew, 
            kmlfile='LocIDNew.kml', 
            name=formatC(LocIDNew$LocIDNew, width=3, flag="0"), 
            description=LocIDNew$siteDescription,
            icon="http://maps.google.com/mapfiles/kml/paddle/pause.png",
            kmlname="LocIDNew",
            kmldescription="Region 1 CyanoMonitoring Locations")
#open file in google earth
  #shell.exec('LocIDNew.kml')


#save shapefile
  writeOGR(LocIDNew,getwd(),'LocIDew', driver="ESRI Shapefile",overwrite_layer=TRUE)

#create LocID2LocIDNew
  a<-read.csv("tempLocations1.csv")
    b<-unique(a[,c('LocID','LocIDNew')]);nrow(b) #221
      length(unique(b$LocID)) #221
      nrow(LocIDNew)#183
  LocID2LocIDNew<-merge(b,LocIDNew@data,by='LocIDNew',all.x=TRUE);nrow(LocID2LocIDNew)#221

        

#save R objects
  save(LocIDNew,LocID2LocIDNew,Lakes,file='Locations.rda')
```

