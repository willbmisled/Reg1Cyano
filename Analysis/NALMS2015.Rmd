---
title: "NALMS2015"
author: "Bryan Milstead"
date: "November 6, 2015"
output: html_document
---
<!---
use these command instead of the knit icon if you want the data and work loaded into the R workspace
  library(knitr)
  setwd('Analysis')
  knit('NALMS2015.rmd')
  -->

To Do List
-------------------------
* everything

```{r setup, include=FALSE, echo=FALSE, cache=FALSE} 
  #########function to install (if needed) and load R packages by list
libs<-c("rgdal","sp","knitr","maptools","rgeos","ggplot2","ggmap") #list of packages to load

installLoad<-function(pck){ #user defined function
    if(!pck%in%installed.packages()){install.packages(pck)}
    require(pck, character.only = TRUE)
  }
lapply(libs,function(x) installLoad(x))  #Load/Install require packages
```

Introduction
-------------------------

This documents contains the analyses and figures for a poster at the 2015 NALMS meeting.

#Data Decisions#

* Only use data from the Beagle Fluorometers
* Restrict to readings recorded in ug/l
* Restrict to integrated tube samples
* For multiple samples for a visit to a lake (includes multiple sites, replicates, and multiple readings) calculate the mean

#Output#

* Map of 2014 sample locations
    - Map of lakes color coded by organization
* Participation stats
    - How many participants? Table Organization by sampleEvent; a sample event is a unique combination of sampleDate and sampleLocation
    - How many lakes? Summary/count information. Lakes by State
    - How many sample dates? Summary/count information. Organization by sample events
* How do phycocyanin measurements change over the course of the summer? How about chl-a? Perhaps a few example WBs in line graph format, or a map that shows the sizes of dots representing Phy and Chl-A concentrations, with a map for the averages of each month (not sure if I’m describing this well, could do better over the phone).
    - Bryan: it will be interesting to see what this look likes.  We will need to address the issues raised at the beginning of the message.  We will also need to consider what to do with outliers.  There are some pretty unreasonable readings in the dataset.
    - DP: Hm, I would defer to you as the data expert on standard processes for dealing with outliers, but understood that they would really mess things up if we’re doing averages. My uninitiated intuition is to pick a value that we feel is a boundary of reasonable vs unreasonable and remove values above that. Could that be done?

Analysis
-------------------------

* Get the data and match it to the locations
* Restrict to Beagle data
* Create sampleDate from sampleYear, sampleMonth, & sampleDay
* Filter out calibration readings
* Filter out Turner fluorometer readings
    
```{r dataStep, include=FALSE, echo=FALSE, cache=FALSE} 
#get monitoring data
  Data2014<-read.csv("../Data2014/Data2014.csv",stringsAsFactors=FALSE)

#get location data
 load('../Data2014/Locations.rda')

#merge locations with the data
  Raw<-merge(Data2014,LocID2LocIDNew,by='LocID',all.x=TRUE)

#restrict to beagles
  table(Raw$Fluorometer,useNA='ifany')
  Raw<-Raw[Raw$Fluorometer=='Beagle',]

#Remove calibration data
  table(Raw$SampleMethod,useNA='ifany')
  Raw<-Raw[Raw$SampleMethod%in%c('Grab','Integrated','VanDorn'),]

#create sampleDate
  Raw$sampleDate<-(Raw$SampleYear*10000)+(Raw$SampleMonth*100)+Raw$SampleDay
```

* Data for counts 
    - includes 'Grab','Integrated', & 'VanDorn' samples
    - units read in RFU or ug/l
    - fresh and frozen samples
    - filtered and unfiltered samples
    
* Create a data.frame of unique sample events (Lake and Date)
* Create a data.frame of unique sampled lakes (Lake)
    
```{r getEventsLakes, include=FALSE, echo=FALSE, cache=FALSE} 
#get unique raw sample events
  events<-unique(Raw[,c('Organization','State','Lon_WBID','sampleDate')]);nrow(events) #301
#get unique lakes
  sampledLakes<-unique(Raw[,c('Organization','State','Lon_WBID')]);nrow(sampledLakes) #104  
```

* Sample events aggregated by
    - Organization
    - State

```{r events, include=TRUE, echo=FALSE, cache=FALSE} 
#aggregate
  table(events$Organization)
  table(events$State)
```

* Lakes sampled aggregated by
    - Organization
    - State

```{r lakes, include=TRUE, echo=FALSE, cache=FALSE} 
#aggregate
  table(sampledLakes$Organization)
  table(sampledLakes$State)
```

* Lake Champlain was the only "lake" sampled in VT. But 19 sites were sampled within the lake.
    * We could say there were 19 "lakes" sampled in VT
    * This increases the number of sample events for State='VT' and Organization='VTDEC' from 33 to 46.
    * or we could just say there was one lake sampled on 33 dates.
* The Charles River was the only MA "lake".  It had four sites but I'm inclined to treat these a single waterbody.

```{r vtEventsLakes, include=FALSE, echo=FALSE, cache=FALSE} 
#get unique VT sample events
  VT<-unique(Raw[Raw$State=='VT',c('LocID','sampleDate')])
  ee<-table(VT$LocID)
  sum(ee) #number of sample events (46) based on location
#get unique MA sample events
  MA<-unique(Raw[Raw$State=='MA',c('LocID','sampleDate')])
  ee<-table(MA$LocID)
  sum(ee) #number of sample events (50) based on location

```

* Get the lake location based on WBID
* Add the site locations for lake Champlain
* convert to SP objects

```{r spatialData, include=FALSE, echo=FALSE, cache=FALSE} 
#WBID lakes
  WBID<-unique(Raw[,c('WBID','Lon_WBID','Lat_WBID')]);nrow(WBID) #104 
    names(WBID)<-c('WBID','Lon','Lat')
  #replace missing WBIDs with integers
    WBID$WBID[which(is.na(WBID$WBID))]<-1:3

# Add VT sites
  VTsites<-unique(Raw[Raw$State=='VT',c('WBID','Lon_LocIDNew','Lat_LocIDNew','LocID')]);nrow(VTsites) #19
    names(VTsites)<-c('WBID','Lon','Lat','VTID')

#combine
  tt<-WBID[(WBID$WBID==22302965)==FALSE,] #remove lake champlain
  tt$VTID<-NA #add dummy
  allLakes<-rbind(tt,VTsites)

#create spatial points dataframes
  WGS84<-CRS("+proj=longlat +datum=WGS84")  #ESRI GCS_WGS_1984 
  WBID<-SpatialPointsDataFrame(coordinates(WBID[,2:3]), WBID, proj4string=WGS84)
    plot(WBID)
  allLakes<-SpatialPointsDataFrame(coordinates(allLakes[,2:3]), allLakes, proj4string=WGS84)
    plot(allLakes)
```


```{r map, include=TRUE, echo=FALSE, cache=FALSE, message=FALSE} 
#create map
  #allLakes

#Get basemap
#need bounding box and increase by a percentage of the area
b <- bbox(allLakes)
b[1, ] <- (b[1, ] - mean(b[1, ])) * 1.35 + mean(b[1, ])
b[2, ] <- (b[2, ] - mean(b[2, ])) * 1.35 + mean(b[2, ])

#create the map

    
baseMap<- ggmap(get_map(location = b, source = "stamen", maptype = "watercolor", crop = T))

us <- map_data("state")
us <- fortify(us, region="region")

gg <- baseMap + geom_map(data=us, map=us,
                    aes(x=long, y=lat, map_id=region, group=group),
                    fill=NA, color="#7f7f7f", size=1)
gg <- gg + geom_point(data=allLakes@data,aes(x=Lon, y=Lat),color="#1515FF",size=3,shape=17)
gg 
```

* Build dataset to evaluate fluorometry readings
* Filter data  
    - ug/l
    - integrated tube samples
    
```{r Keep, include=FALSE, echo=FALSE, cache=FALSE, message=FALSE} 
#restrict to ug/l
  table(Raw$Units,useNA='ifany')
  Keep<-Raw[Raw$Units=='ug/l',]
  nrow(Keep) #6671
  
#restrict to integrated tube samples
  table(Raw$SampleMethod,useNA='ifany')
  Keep<-Raw[Raw$SampleMethod=='Integrated',]
  nrow(Keep) #6536
  
#restrict to integrated tube samples
  table(Raw$Depth,useNA='ifany')
  Keep<-Raw[Raw$SampleMethod=='Integrated',]
  nrow(Keep) #6536
```

* Not sure what to do about depth-here is a table of samples by depth
* For now I think I'll keep them all.

```{r Depth, include=TRUE, echo=TRUE, cache=FALSE, message=FALSE} 
table(Raw$Depth,useNA='ifany')
```
  
* What about rep?
* Keep them all for now but work with means.

```{r rep, include=TRUE, echo=TRUE, cache=FALSE, message=FALSE} 
table(Raw$Rep,useNA='ifany')
```
    
* What about filtration?

```{r filter, include=TRUE, echo=TRUE, cache=FALSE, message=FALSE} 
table(Raw$Filtered,useNA='ifany')
```    
    
* What about freezing?

```{r frozen, include=TRUE, echo=TRUE, cache=FALSE, message=FALSE} 
table(Raw$Frozen,Raw$Parameter,useNA='ifany')
```

* Let's look at the distrution of values for the four combinations of filtered and frozen
* assign conditions (cond)
    - Frozen/Filtered
    - Fresh/Filtered
    - Frozen/Unfiltered
    - Fresh/Unfiltered
* Get means by Lake
* Create lakeID
    - for most lakes this is the WBID
    - for CRWA this will be 99 (no WBID for the charles river)
    - for SiteID=='15924-M' lakeID=SiteID (this lake not in NHDplus)
    - for lake Champlain (WBID==22302965) lakeID=SiteID
* calculate mean values for beagle readings by c('lakeID','sampleDate','SampleMonth','Organization','State','cond','Parameter')


```{r cond, include=FALSE, echo=FALSE, cache=FALSE, message=FALSE} 
#assisgn condition
cond<-rep(NA,nrow(Keep))
cond[Keep$Frozen==TRUE & Keep$Filtered==TRUE]<-'Frozen\nFiltered'
cond[Keep$Frozen==FALSE & Keep$Filtered==TRUE]<-'Fresh\nFiltered'
cond[Keep$Frozen==TRUE & Keep$Filtered==FALSE]<-'Frozen\nUnfiltered'
cond[Keep$Frozen==FALSE & Keep$Filtered==FALSE]<-'Fresh\nUnfiltered'
cond[is.na(Keep$Frozen) | is.na(Keep$Filtered)]<-NA

Keep$cond<-cond

#remove missing values
a<-na.exclude(Keep[,c('Parameter','cond','Value','SampleMonth')])

#create lakeID
Keep$lakeID<-Keep$WBID
table(Keep$lakeID,useNA='ifany')

Keep$lakeID[Keep$WBID==22302965 & !is.na(Keep$WBID)]<-Keep$SiteID[Keep$WBID==22302965 & !is.na(Keep$WBID)]

Keep$lakeID[Keep$SiteID=='15924-M']<-'15924-M'
Keep$lakeID[Keep$Organization=='CRWA']<-99

#calc means
means<-aggregate(Keep$Value,list(Keep$lakeID,Keep$sampleDate,Keep$SampleMonth,Keep$Organization,Keep$State,Keep$cond,Keep$Parameter),mean,na.rm=TRUE)
names(means)<-c('lakeID','sampleDate','SampleMonth','Organization','State','cond','Parameter','mean')
```

* create box plots for each parameter by condition, Organization, State, & Month
```{r boxes1, include=FALSE, echo=FALSE, cache=FALSE, message=FALSE} 
#ylabels
cLab<-paste('Chlorphyll (',expression('\U03BC'),'g/l)',sep='')
pLab<-paste('Phycocyanin (',expression('\U03BC'),'g/l)',sep='')

#chlorophyll

cCond<-ggplot(means[means$Parameter=='Chlorophyll',], aes(x=cond, y=mean)) + geom_boxplot() + scale_y_log10(cLab,breaks=c(1,10,100,1000),limits=c(.01,10000)) + scale_x_discrete('Condition') 

cOrg<-ggplot(means[means$Parameter=='Chlorophyll',], aes(x=Organization, y=mean)) + geom_boxplot() + scale_y_log10(cLab,breaks=c(1,10,100,1000),limits=c(.01,10000)) + scale_x_discrete('Organization') 

cSt<-ggplot(means[means$Parameter=='Chlorophyll',], aes(x=State, y=mean)) + geom_boxplot() + scale_y_log10(cLab,breaks=c(1,10,100,1000),limits=c(.01,10000)) + scale_x_discrete('State') 

cMo<-ggplot(means[means$Parameter=='Chlorophyll',], aes(x=as.factor(SampleMonth), y=mean)) + geom_boxplot() + scale_y_log10(cLab,breaks=c(1,10,100,1000),limits=c(.01,10000)) + scale_x_discrete('Month') 

pCond<-ggplot(means[means$Parameter=='Phycocyanin',], aes(x=cond, y=mean)) + geom_boxplot() + scale_y_log10(pLab,breaks=c(1,10,100,1000),limits=c(.01,10000)) + scale_x_discrete('') 

pOrg<-ggplot(means[means$Parameter=='Phycocyanin',], aes(x=Organization, y=mean)) + geom_boxplot() + scale_y_log10(pLab,breaks=c(1,10,100,1000),limits=c(.01,10000)) + scale_x_discrete('Organization') 

pSt<-ggplot(means[means$Parameter=='Phycocyanin',], aes(x=State, y=mean)) + geom_boxplot() + scale_y_log10(pLab,breaks=c(1,10,100,1000),limits=c(.01,10000)) + scale_x_discrete('State') 

pMo<-ggplot(means[means$Parameter=='Phycocyanin',], aes(x=as.factor(SampleMonth), y=mean)) + geom_boxplot() + scale_y_log10(pLab,breaks=c(1,10,100,1000),limits=c(.01,10000)) + scale_x_discrete('Month') 
```

```{r boxes2, include=TRUE, echo=FALSE, cache=FALSE, message=FALSE, warning=FALSE} 
cCond
cOrg
cSt
cMo
pCond
pOrg
pSt
pMo
```


Data Definitions
-------------------------

Data.frame "Raw" has `r nrow(Raw)` observations

Field  | Units | Description
------------- | ------------- | -------------
**ID:**|(integer)|Unique Identifier for each observation
**Organization:**|(text)|Name of the organization responsible for collecting the samples-e.g. Vermont DEC
**State:**|(lookup)|Two letter state code for site
**YourName:**|(text)|Name of the person entering the data
**SiteID:**|(text)|site ID from the Organization collecting the data (if they have one)
**WaterbodyName:**|(text)|Name of the sampled lake.
**SiteLocation:**|(text)|Some organizations have site names within a lake.
**SampleLocation:**|(lookup)|Where (in the lake) was the sample collected followed by the replicate number? WithinLake=WL1, WL2, or WL3; ShoreSide=SS1, SS2, SS3; Can also add Calibration or Blank for validation readings or Other.
**SampleYear:**|(YYYY)|Year sample was collected in format YYYY (e.g., 2014)
**SampleMonth:**|(MM)|Month sample was collected in integer format (e.g., months 1 to 12 )
**SampleDay:**|(DD)|Day sample was collected in integer format (e.g., day 1 to 31 )
**SampleHour:**|(HH)|Hour sample was taken in 24 hour format
**SampleMinutes:**|(MM)|Minute sample was taken in integer format
**NameOfSamplers:**|(text)|Names of the field crew separated by commas.
**WeatherConditions:**|(text)|General Weather conditions separated by commas.  E.g., Cloudy, Windy, Cold
**SampleMethod:**|(lookup)|How was the sample collected? Grab = Grab sample for surface blooms; Composite =Composite; Integrated = Integrated tube sample; Validation = Use this for Blanks and Calibration Standards; Other = give details in the comments section.
**Depth:**|(integer)|Within Lake samples are at 3m and Shoreside are at 1m.  If samples taken at different depths not the depth here and enter details in the comments section.  Leave blank for standards and blanks.
**Filtered:**|(TRUE/FALSE)|Was the sample filtered?
**Frozen:**|(TRUE/FALSE)|Was the sample frozen?
**Parameter:**|(lookup)|Phycocyanin or Chlorophyll?
**Value:**|(decimal)|Reading from the fluorometer
**Units:**|(lookup)|What were the units recorded.  If not "RFU" or "µ/L" flag the entry and add comment with the units used. 
**Rep:**|(integer)|If you made more than one measurement per sample or took more than one sample per site assign a replicate number to each observations and add notes in the comment field.
**Fluorometer:**|(lookup)|Type of fluorometer used?
**AnalysisYear:**|(YYYY)|Year sample was analyzed in format YYYY (e.g., 2014)
**AnalysisMonth:**|(MM)|Month sample was analyzed in integer format (e.g., months 1 to 12 )
**AnalysisDay:**|(DD)|Day sample was analyzed in integer format (e.g., day 1 to 31 )
**AnalysisHour:**|(HH)|Hour sample was analyzed in 24 hour format
**AnalysisMinutes:**|(MM)|Minute sample was analyzed in integer format
**GPSType:**|(text)|How was the location determined.  GPS (type), map, or google?
**Photos:**|(TRUE/FALSE)|Where photos taken?
**LocIDNew:**|(integer)|Unique Identifier for the Location.  See "Locations2014.rmd"
**Lon_LocIDNew**|(Decimal Degrees)|Longitude of the sample site identified by "LocIDNew"
**Lat_LocIDNew**|(Decimal Degrees)|Latitude of the sample site identified by "LocIDNew"
**WBID:**|(integer)|Unique Identifier for the Lake from the "WaterbodyDatabase.mdb".  See "Locations2014.rmd"
**Lon_WBID**|(Decimal Degrees)|Longitude of the centroid for the Lake identified by "WBID"
**Lat_WBID**|(Decimal Degrees)|Latitude of the centroid for the Lake identified by "WBID"
**Flag:**|(TRUE/FALSE)|Add a flag for any data line that needs further validation or processing
**Comments:**|(text)|Add details of flags or any notes about the data line or sample.





